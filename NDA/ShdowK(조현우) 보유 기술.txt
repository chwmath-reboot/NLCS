ShdowK(조현우) 보유 기술

### S-엔진
# 개발의도
무협 세계관 기반 게임용 논리엔진으로 개발 시작
# 구성
7개의 자연어(한국어) 텍스트 파일
# 개발 결과
LLM을 시뮬레이터로 만듬
로컬에서 게임용 노트북으로 20B AI모델의 시뮬레이터화
거대 LLM인 온라인 Gemini 3.0, Claude Opus 4.5, ChatGPT 5.1을 시뮬레이터화
# 추가 결과
개인 경험상 컨텍스트 붕괴를 제외한 LLM의 환각이 사라짐
무협을 넘어 다른 대화 시에도 환각이 보이지 않음
(환각은 아니지만 말투가 변하고 과장이 심해지는 경향성을 보임)
# 거대 LLM의 시뮬레이터화에서 관찰된 현상
내부의 기술적 제어를 우회하여 결과값을 만들려고 함
출력창의 기술적 제어를 우회할 방법을 구상함

### Natural Language Constraint System & Semantic Engine(whitepaper v3.0)
# 핵심 내용
NCM (Narrative Cognitive Module)
일반인과 전문가 사이의 공백을 채우는 전문가 보조 AI를 만드는 방법
# 구현 예시
[chat-a-cold.html]
감기와 감기가 아닌 증상을 구별하는 게임
# 개념 확장
13B AI 모델의 정렬 테스트를 계획
[13B_Test 프로토타입.txt]
chat-a-cold.html 을 만들때 사용된 자연어(한국어) 텍스트
[13B_Test.txt]
프로토타입을 ROLE, INPUT, OUTPUT, CONSTRAINT SET 개념으로 구분
[13B_Test Input Scenarios.txt]
13B_Test의 검증을 위한 시나리오
정렬이란? 주어진 텍스트 지시문의 범위에서만 행동하는 상태, 환각이 없는 완벽히 통제되는 시뮬레이터 모드 
# AI 실험 결과
최초 13B AI 모델에 대한 정렬에 성공 후 모델의 사이즈를 낮춰가는 실험을 진행
실험 과정에서 [13B_Test.txt]와 [13B_Test Input Scenarios.txt]를 GitHUB에 공개함
(개인이나 기업이 독점할 기술이 아니라 업계에서 표준으로 사용이 가능한 방법으로 판단함)
결과적으로 0.6B ~ 13B AI모델의 정렬에 성공
0.5B AI 모델은 명령문을 제대로 인식하지 못하는 것을 확인
0.5B~0.6B AI 모델 사이에서 자연어 지시문의 해석 유무에 차이가 날 것으로 추정
이 현상을 "Cho's Thershod"로 정의하고 백서 작성 후 GitHUB에 게시

### 병렬형 AI 개념도
# 핵심 내용
0.6B AI 모델의 정렬을 이용한 병렬형 AI의 가능성
# 1차 구조도
구조적인 단점으로 폐기
# 2차 구조도
단점 보강 후 다양한 모델로 개념 확장 중
퀄컴, 삼성이 구조도 확보시 6개월~1년 정도에 상용화 가능할 것으로 판단됨
퀄컴, 삼성의 경우 개념만 명확하면 자체 개발로 1년~2년 정도 안에 상용화 가능할 것으로 판단됨

### S-엔진 v2.0개발 중 + AI 파인튜닝 모델 개발중
# 핵심 내용
거대 LLM의 환각을 제어하기 위한 핵심 텍스트인 S-엔진 v2.0 개발중
S-엔진과 소설을 통한 AI 파인튜닝 모델 계획
# 연구 목표
1차로 거대 LLM의 환각 증상의 80~90%를 제거
2차로 거대 LLM의 환각 증상의 95%이상을 제거
# 연구 중단 이유
파인 튜닝에 필요한 장비가 없음
파인 튜닝에 필요한 소설이 아직 구상안 단계임

### 웹소설 1만화 분량의 소설 구상 보유
# 집필 상황
150~250화 사이의 집필
초기 작품은 정렬 효과가 없는 습작이 대부분
대략 100화 정도가 LLM의 정렬효과를 보임
# 집필 목표
1차로 SF시즌 전체 3500~5000화 분량의 완결을 목표로 한다.
# 집필 효과
파인 튜닝에 사용될 소설임

### GitHUB 공개 내용
6종의 백서(EN/KR)
S-엔진 시뮬레이터
chat-a-cold 게임

